# üöÄ Projeto de Previs√£o de Churn em Telecom

## üìù Descri√ß√£o do Projeto

Este projeto tem como objetivo principal desenvolver e avaliar modelos de classifica√ß√£o para prever o **churn** (abandono) de clientes em uma empresa de telecomunica√ß√µes. Utilizou-se uma base de dados real do Kaggle para treinar e comparar diferentes abordagens, desde modelos de Machine Learning tradicionais at√© arquiteturas de Deep Learning modernas.

O foco da avalia√ß√£o √© a m√©trica **KS (Kolmogorov-Smirnov)**, que mede a capacidade de um modelo de separar clientes que d√£o churn daqueles que n√£o d√£o. Essa √© uma m√©trica crucial para o neg√≥cio, pois indica qu√£o bem o modelo pode segmentar a base de clientes para a√ß√µes de reten√ß√£o.

### üéØ Objetivos Principais

1. **Pr√©-processar a base de dados**: Tratar valores ausentes, realizar codifica√ß√£o de vari√°veis categ√≥ricas com `TargetEncoder` e normalizar as features num√©ricas.  
2. **Dividir os dados**: Criar conjuntos de treino (50%), valida√ß√£o (25%) e teste (25%) de forma estratificada para manter a propor√ß√£o da vari√°vel alvo.  
3. **Implementar e treinar modelos**: Explorar diversos modelos, incluindo `Random Forest`, `Gradient Boosting`, e redes neurais como `MLP`, `TabPFN` e `STab`.  
4. **Otimizar hiperpar√¢metros**: Utilizar a biblioteca `Optuna` para encontrar os melhores hiperpar√¢metros para cada modelo, com foco na maximiza√ß√£o do score KS.  
5. **Avaliar o desempenho**: Analisar os resultados de forma detalhada, utilizando m√©tricas como KS, AUC-ROC, Acur√°cia, Precis√£o, Recall e F1-Score no conjunto de teste.  
6. **Documentar e comparar**: Elaborar uma tabela comparativa para identificar o modelo mais perform√°tico para o objetivo de neg√≥cio.

---

## üõ†Ô∏è Modelos e Pr√©-processamento

### Pr√©-processamento e Balanceamento

O pipeline de pr√©-processamento foi desenhado para evitar vazamento de dados (*data leakage*) e para preparar a base de dados de forma robusta:

- **Divis√£o Estratificada**: O dataset foi dividido em treino (50%), valida√ß√£o (25%) e teste (25%) com `train_test_split` usando `stratify=y` para garantir que a propor√ß√£o de clientes com e sem churn fosse mantida em todos os conjuntos.  
- **Codifica√ß√£o e Normaliza√ß√£o**: Para lidar com dados categ√≥ricos, foi aplicado `TargetEncoder`, que utiliza a m√©dia da vari√°vel alvo para codificar as categorias. Para as vari√°veis num√©ricas, o `StandardScaler` foi utilizado para padronizar os dados. Ambas as transforma√ß√µes foram ajustadas (fit) **apenas no conjunto de treino**.  
- **Balanceamento de Classes**: Como a base de dados era desbalanceada, foi usado o `SMOTE` (`Synthetic Minority Over-sampling Technique`) para gerar amostras sint√©ticas da classe minorit√°ria (clientes com churn), criando um conjunto de treino balanceado para os modelos.

### Modelos de Classifica√ß√£o

O projeto explorou uma gama de modelos, dos mais tradicionais aos mais modernos baseados em Deep Learning:

- **Random Forest**: Um modelo de ensemble robusto que serviu como baseline de alta performance. Seus hiperpar√¢metros foram ajustados com `Optuna`.  
- **Gradient Boosting**: Outro modelo de ensemble poderoso, com otimiza√ß√£o de hiperpar√¢metros via `Optuna`, considerado um dos modelos mais fortes para dados tabulares.  
- **MLP (Multi-Layer Perceptron)**: Uma rede neural b√°sica, mas eficaz, implementada com TensorFlow/Keras e otimizada com `Optuna`.  
- **TabPFN (Tabular PFN)**: Um modelo Transformer pr√©-treinado, que n√£o requer otimiza√ß√£o de hiperpar√¢metros e √© projetado para funcionar "out-of-the-box" em dados tabulares. O modelo tem uma limita√ß√£o de 1024 amostras, portanto, um subconjunto dos dados foi utilizado.  
- **STab (Tabular Transformer)**: Outro modelo baseado em Transformer, mas que necessita de treinamento do zero. Implementado com PyTorch, foi avaliado ap√≥s uma otimiza√ß√£o com `Optuna`.

---

## üèÜ Compara√ß√£o de Desempenho no Conjunto de Teste

A tabela abaixo resume o desempenho final de cada modelo, ordenado pela m√©trica-chave **KS**.

| Modelo           | KS     | AUC    | MSE    | Accuracy | Precision | Recall  | F1-Score |
|:-----------------|:-------|:-------|:-------|:---------|:----------|:--------|:---------|
| Gradient Boosting | 0.5429 | 0.8420 | 0.1358 | 0.7978   | 0.6546    | 0.5032  | 0.5690   |
| Random Forest    | 0.5401 | 0.8418 | 0.1360 | 0.8007   | 0.6667    | 0.4968  | 0.5693   |
| STab             | 0.5397 | 0.8436 | 0.1369 | 0.7939   | 0.6390    | 0.5118  | 0.5684   |
| TabPFN           | 0.5395 | 0.8423 | 0.1358 | 0.8052   | 0.6574    | 0.5546  | 0.6016   |
| MLP              | 0.5222 | 0.8301 | 0.1425 | 0.7848   | 0.6189    | 0.4904  | 0.5472   |

### An√°lise dos Resultados

- **Lideran√ßa do Gradient Boosting**: Com o maior score **KS (0.5429)**, o `Gradient Boosting` se mostrou o modelo mais eficaz em separar as classes de clientes com alta e baixa probabilidade de churn. Isso o torna a escolha ideal para o objetivo central do projeto, que √© identificar grupos de alto risco com precis√£o para direcionar a√ß√µes de reten√ß√£o.  
- **Destaque do TabPFN**: O `TabPFN` apresentou o melhor **Recall (0.5546)**, o que significa que ele foi o melhor em identificar corretamente os clientes que de fato dariam churn. Al√©m disso, alcan√ßou a maior **Acur√°cia (0.8052)** e **F1-Score (0.6016)**, demonstrando um √≥timo equil√≠brio entre as m√©tricas.  
- **For√ßa do Random Forest**: O `Random Forest` alcan√ßou a maior **Precis√£o (0.6667)**, sendo a melhor op√ß√£o quando o custo de uma interven√ß√£o indevida √© alto.  
- **Redes Neurais Tradicionais**: O `MLP` ficou em √∫ltimo lugar, indicando que modelos mais complexos de Deep Learning (como os baseados em Transformers) ou modelos de ensemble (como Gradient Boosting e Random Forest) s√£o mais adequados para a natureza dos dados tabulares deste problema.

---

## üìå Conclus√£o e Pr√≥ximos Passos

O **Gradient Boosting** √© o modelo recomendado como a solu√ß√£o principal, pois sua superioridade na m√©trica **KS** o torna o mais adequado para o problema de segmenta√ß√£o de churn. No entanto, o **TabPFN** e o **Random Forest** tamb√©m se destacam em cen√°rios de neg√≥cio espec√≠ficos, oferecendo um leque de op√ß√µes dependendo da prioridade (cobertura vs. precis√£o).

Para aprimorar a solu√ß√£o, as seguintes etapas s√£o sugeridas:

- **Refinamento de Hiperpar√¢metros**: Explorar mais a fundo o espa√ßo de busca do `Optuna` para o `Gradient Boosting`, talvez com um foco em aumentar o `recall` sem comprometer o KS.  
- **T√©cnicas de Ensemble**: Testar combina√ß√µes (stacking ou blending) entre os modelos l√≠deres, como `Gradient Boosting` e `TabPFN`, para buscar um desempenho ainda mais robusto.  
- **Engenharia de Features**: Criar novas vari√°veis a partir dos dados existentes (ex: tempo de perman√™ncia vs. gastos totais) para aumentar o poder preditivo dos modelos.
